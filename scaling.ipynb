{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877c0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Custom imports\n",
    "import wrangle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12995465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>fips_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3633</td>\n",
       "      <td>296425</td>\n",
       "      <td>2005</td>\n",
       "      <td>6941.39</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1620</td>\n",
       "      <td>847770</td>\n",
       "      <td>2011</td>\n",
       "      <td>10244.94</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2077</td>\n",
       "      <td>646760</td>\n",
       "      <td>1926</td>\n",
       "      <td>7924.68</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1244</td>\n",
       "      <td>169471</td>\n",
       "      <td>1950</td>\n",
       "      <td>2532.88</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1300</td>\n",
       "      <td>233266</td>\n",
       "      <td>1950</td>\n",
       "      <td>3110.99</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedroomcnt  bathroomcnt  square_feet  taxvaluedollarcnt  yearbuilt  \\\n",
       "0           4          2.0         3633             296425       2005   \n",
       "1           3          4.0         1620             847770       2011   \n",
       "2           3          2.0         2077             646760       1926   \n",
       "6           3          1.0         1244             169471       1950   \n",
       "7           3          2.0         1300             233266       1950   \n",
       "\n",
       "   taxamount    fips_name  \n",
       "0    6941.39  Los Angeles  \n",
       "1   10244.94  Los Angeles  \n",
       "2    7924.68  Los Angeles  \n",
       "6    2532.88  Los Angeles  \n",
       "7    3110.99  Los Angeles  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrangle function\n",
    "df = wrangle.wrangle_zillow()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d0b8d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1169459, 7) (501197, 7) (417665, 7)\n"
     ]
    }
   ],
   "source": [
    "# Splitting\n",
    "train_validate, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "train, validate = train_test_split(train_validate, test_size=.3, random_state=123)\n",
    "print(train.shape, validate.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fab165",
   "metadata": {},
   "source": [
    "#### 1. Apply the scalers we talked about in this lesson to your data and visualize the results for the unscaled and scaled distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31bdb21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['bedroomcnt', 'bathroomcnt', 'square_feet', 'taxvaluedollarcnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d7bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = train.copy() # This creates a NEW COPY\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled[columns_to_scale] = scaler.fit_transform(train[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f203f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d31e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "train                  # Same thing, just an additional copy to mess with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9381f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train.bedroomcnt)\n",
    "plt.title('Distribution of Bedrooms Before MinMaxScaler')\n",
    "plt.xlabel('Number of Bedrooms')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbfd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_scaled.bedroomcnt)\n",
    "plt.title('Distribution of Bedrooms After MinMaxScaler')\n",
    "plt.xlabel('Number of Bedrooms')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5989498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_scaler(scaler, df, columns_to_scale, bins=10):\n",
    "    fig, axs = plt.subplots(len(columns_to_scale), 2, figsize=(16,9))\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "    for (ax1, ax2), col in zip(axs, columns_to_scale):\n",
    "        ax1.hist(df[col], bins=bins)\n",
    "        ax1.set(title=f'{col} before scaling', xlabel=col, ylabel='count')\n",
    "        ax2.hist(df_scaled[col], bins=bins)\n",
    "        ax2.set(title=f'{col} after scaling with {scaler.__class__.__name__}', xlabel=col, ylabel='count')\n",
    "    plt.tight_layout()\n",
    "#    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bafa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler Applied\n",
    "visualize_scaler(scaler=MinMaxScaler(), df=train, columns_to_scale=columns_to_scale, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6966ac4b",
   "metadata": {},
   "source": [
    "#### Takeaway: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98456a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler Applied\n",
    "visualize_scaler(scaler=StandardScaler(), df=train, columns_to_scale=columns_to_scale, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RobustScaler Applied\n",
    "visualize_scaler(scaler=RobustScaler(), df=train, columns_to_scale=columns_to_scale, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d8a4f3",
   "metadata": {},
   "source": [
    "#### 2. Apply the .inverse_transform method to your scaled data. Is the resulting dataset the exact same as the original data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "original_data = train[['taxvaluedollarcnt']]\n",
    "scaled_data = scaler.fit_transform(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9178b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bbf956",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(scaled_data)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b682a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(scaler.inverse_transform(scaled_data) == original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1390869",
   "metadata": {},
   "source": [
    "#### 3. Read the documentation for sklearn's QuantileTransformer. Use normal for the output_distribution and apply this scaler to your data. Visualize the result of your data scaling.\n",
    "\n",
    "This method transforms the features to follow a uniform or a normal distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers: this is therefore a robust preprocessing scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantileTransformer Applied\n",
    "visualize_scaler(scaler=QuantileTransformer(output_distribution='normal'), df=train, columns_to_scale=columns_to_scale, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353fb5bb",
   "metadata": {},
   "source": [
    "#### 4. Use the QuantileTransformer, but omit the output_distribution argument. Visualize your results. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantileTransformer Applied\n",
    "visualize_scaler(scaler=QuantileTransformer(), df=train, columns_to_scale=columns_to_scale, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6056d9b",
   "metadata": {},
   "source": [
    "#### 5. Based on the work you've done, choose a scaling method for your dataset. Write a function within your prepare.py that accepts as input the train, validate, and test data splits, and returns the scaled versions of each. Be sure to only learn the parameters for scaling from your training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, \n",
    "               validate, \n",
    "               test, \n",
    "               columns_to_scale=['bedroomcnt', 'bathroomcnt', 'taxvaluedollarcnt', 'calculatedfinishedsquarefeet'],\n",
    "               return_scaler=False):\n",
    "    '''\n",
    "    Scales the 3 data splits. \n",
    "    Takes in train, validate, and test data splits and returns their scaled counterparts.\n",
    "    If return_scalar is True, the scaler object will be returned as well\n",
    "    '''\n",
    "    train_scaled = train.copy()\n",
    "    validate_scaled = validate.copy()\n",
    "    test_scaled = test.copy()\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train[columns_to_scale])\n",
    "    \n",
    "    train_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(train[columns_to_scale]),\n",
    "                                                  columns=train[columns_to_scale].columns.values).set_index([train.index.values])\n",
    "                                                  \n",
    "    validate_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(validate[columns_to_scale]),\n",
    "                                                  columns=validate[columns_to_scale].columns.values).set_index([validate.index.values])\n",
    "    \n",
    "    test_scaled[columns_to_scale] = pd.DataFrame(scaler.transform(test[columns_to_scale]),\n",
    "                                                 columns=test[columns_to_scale].columns.values).set_index([test.index.values])\n",
    "    \n",
    "    if return_scaler:\n",
    "        return scaler, train_scaled, validate_scaled, test_scaled\n",
    "    else:\n",
    "        return train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e21c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, train_scaled, validate_scaled, test_scaled = scale_data(train, validate, test, return_scaler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f579cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db87dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
